# BioREASONIC Benchmark Configuration
# Used by both BioKGBench and BioResonKGBench evaluations

# =============================================================================
# Neo4j Connection
# =============================================================================
neo4j:
  url: "10.73.107.108"
  port: 7687
  user: "neo4j"
  password: "password123"
  encrypted: false

# =============================================================================
# LLM API Configuration
# =============================================================================
llm:
  # Default provider: "openai", "claude", "together", or "none" (rule-based)
  provider: "openai"

  # OpenAI Models
  openai:
    api_key: "${OPENAI_API_KEY}"  # Set via environment variable
    models:
      gpt-4o: "gpt-4o"
      gpt-4o-mini: "gpt-4o-mini"
      gpt-4.1: "gpt-4-turbo"
      gpt-4.1-mini: "gpt-4-turbo-preview"
    default_model: "gpt-4o"
    temperature: 0.0
    max_tokens: 1000

  # Anthropic Claude Models
  claude:
    api_key: "${ANTHROPIC_API_KEY}"
    models:
      claude-3-haiku: "claude-3-haiku-20240307"
      claude-3-sonnet: "claude-3-sonnet-20240229"
      claude-3.5-sonnet: "claude-3-5-sonnet-20241022"
    default_model: "claude-3-haiku"
    temperature: 0.0
    max_tokens: 1000

  # Together AI Models (Llama, Qwen, DeepSeek)
  together:
    api_key: "${TOGETHER_API_KEY}"
    models:
      llama-3.1-8b: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"
      llama-3.1-70b: "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo"
      qwen-2.5-7b: "Qwen/Qwen2.5-7B-Instruct-Turbo"
      qwen-2.5-72b: "Qwen/Qwen2.5-72B-Instruct-Turbo"
      deepseek-v3: "deepseek-ai/DeepSeek-V3"
    default_model: "llama-3.1-8b"
    temperature: 0.0
    max_tokens: 1000

# =============================================================================
# Paths (relative to BioREASONIC root)
# =============================================================================
paths:
  # Main KG config
  kg_config: "configs/kg_config.yml"

  # BioKGBench
  biokgbench:
    root: "benchmarks/01_BioKGBench"
    config: "benchmarks/01_BioKGBench/config"
    src: "benchmarks/01_BioKGBench/src"
    results: "benchmarks/01_BioKGBench/results"
    tutorials: "benchmarks/01_BioKGBench/tutorials"

  # BioResonKGBench
  bioresonkgbench:
    root: "benchmarks/02_BioResonKGBench"
    data: "benchmarks/02_BioResonKGBench/data"
    config: "benchmarks/02_BioResonKGBench/config"
    src: "benchmarks/02_BioResonKGBench/src"
    results: "benchmarks/02_BioResonKGBench/results"
    tutorials: "benchmarks/02_BioResonKGBench/tutorials"

# =============================================================================
# Evaluation Settings
# =============================================================================
evaluation:
  # Save detailed predictions
  save_predictions: true

  # Compare rule-based vs LLM
  compare_modes: true

  # Verbose output
  verbose: false

  # Batch size for processing
  batch_size: 10

  # Timeout per question (seconds)
  timeout: 60

# =============================================================================
# Metrics to Compute
# =============================================================================
metrics:
  - f1
  - exact_match
  - hits_1
  - hits_5
  - hits_10
  - mrr
  - executability
  - coverage
